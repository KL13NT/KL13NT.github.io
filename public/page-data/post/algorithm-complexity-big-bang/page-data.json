{"componentChunkName":"component---src-templates-post-js","path":"/post/algorithm-complexity-big-bang","webpackCompilationHash":"5600b8e04d9b3de6d381","result":{"data":{"markdownRemark":{"html":"<h4>Ever wondered what Big O Notation is? It can be a confusing topic, but I'll do my best here to explain it clearly.</h4>\n<p>Big O notation is used in Computer Science to describe the performance or complexity of an algorithm. Big O specifically describes the worst-case scenario, and can be used to describe the execution time required or the space used (e.g. in memory or on disk) by an algorithm. I'll cover some complexities that are widely seen.</p>\n<h2>O(1) CONSTANT</h2>\n<p>This type of algorithms will always execute in the same time (or space) regardless of the size of the input data set. For instance <code>if(x % 2 === 1) return 'odd';</code>. </p>\n<blockquote>\n<p><span>This is not always the case though.  </span></p>\n</blockquote>\n<h2>O(n) LINEAR</h2>\n<p>Describes an algorithm whose time required will grow linearly and in direct proportion to the size of the input data set. An example is finding the largest item on an unsorted array. The function will always need to go over all elements before it returns for sure that an element is the largest. </p>\n<h2>O(n^2) QUADRATIC</h2>\n<p>Represents an algorithm whose performance is directly proportional to the square of the size of the input data set. This is common with algorithms that involve nested iterations over the data set. Deeper nested iterations will result in O(n^3), O(n^4) etc. An example is finding a duplicated element in an array. Bubble Sort is also an example since it involves nested loops.</p>\n<h2>O(2^n) EXPONENTIAL</h2>\n<p>Denotes that an algorithm calculations double with each additon to the input data set. For example, finding the \"Power Set\" of [a, b] yields [ , a, b, ab]. Now use [a, b, c]. This will yield the power set of [a, b] and the power set of [a, b] with c appended at the end which is P[a, b] * c = [ , a, b, c, ab, ac, bc, abc]. Meaning that the length of the resulting set is doubled every time you add 1 to the input length. </p>\n<h2>O(log n) LOGARITHMIC</h2>\n<p>This is one of the most efficient algorithms to exist. An example of it is \"Binary Search\". </p>\n<blockquote>\n<p><span>In computer science, binary search is a search algorithm that finds the position of a target value within a sorted array. Binary search compares the target value to the middle element of the array.<br>â€” Wikipedia</p>\n</blockquote>\n<h2>O(n log n) LINEARITHMIC</h2>\n<p>This one is slightly slower than linear O(N) but is more efficient than O(n^2). An example of it is \"Merge Sort\". Merge Sort is a Divide and Conquer algorithm. It divides input array in two halves, calls itself for the two halves and then merges the two sorted halves.</p>\n<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/c/cc/Merge-sort-example-300px.gif\" alt=\"GIF illustrating merge sort\"><span class=\"image-description\">A simple illustration of Merge Sort</span></p>\n<h2>O(n!) FACTORIAL</h2>\n<p>You want to stay away from this. Imagine a normal mathematical factorial of 5!. </p>\n<pre><code>5! = 120 \n6! = 720\n7! = 5040\n8! = 40320 \n9! = 362880\n10! = 3,628,800\n</code></pre>\n<p>That grew a lot! Factorial algorithms output data that <strong>grows</strong> with a very steep upwards curve at tiny changes in its input. </p>\n<h2>O(n^c) c > 1; POLYNOMIAL</h2>\n<p>This one is basically any algorithm that involves a running time bigger than O(n^1) such as O(n^2) QUADRATIC.</p>\n<h2>Final notes</h2>\n<p>This was a quick peek at the different types of algorithm complexities. Those values are not static. Every algorithm could either range between different complexities or take a single one. Visiting the Wikipedia page for each of those you'll find some more info about that algorithm complexity.</p>","frontmatter":{"date":"May 04, 2019","path":"/post/algorithm-complexity-big-bang","title":"Algorithm complexity and the Big Bang(n)","description":"Ever wondered what O(n) means? I'll take you through a tiny journey to learn more about algorithm complexity and the Big O Notation.","author":"Nabil Tharwat @Nabil_Tharwat16","length":2700,"image":{"childImageSharp":{"fluid":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAANABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAECBP/EABYBAQEBAAAAAAAAAAAAAAAAAAEDBP/aAAwDAQACEAMQAAABh1VsaMAP/8QAGhAAAgIDAAAAAAAAAAAAAAAAAQIAAxESE//aAAgBAQABBQJBvbrzh6iLl7MA2Es7f//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oACAEDAQE/AUf/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAbEAACAwADAAAAAAAAAAAAAAAAARESMQIhcf/aAAgBAQAGPwJWWl9Omn6PjMFEo0bmD//EABsQAQACAwEBAAAAAAAAAAAAAAEAESExQVFh/9oACAEBAAE/Ibk5x8l7UGvPJaoLiMx2F0JyK+Bch3UtFy0T/9oADAMBAAIAAwAAABCgH//EABcRAAMBAAAAAAAAAAAAAAAAAAARIWH/2gAIAQMBAT8QqNI//8QAFREBAQAAAAAAAAAAAAAAAAAAECH/2gAIAQIBAT8Qh//EABwQAQACAgMBAAAAAAAAAAAAAAEAESFBMVGBof/aAAgBAQABPxAgRybYE38jl3qvMWLo7Yln+i9VEfQbrtVV7KLe5nDT2cxdBME//9k=","aspectRatio":1.5296367112810707,"src":"/static/e0b6e8978e250d40d864acc016ecc9f4/51ce9/markdownTestHeader.jpg","srcSet":"/static/e0b6e8978e250d40d864acc016ecc9f4/35dbd/markdownTestHeader.jpg 197w,\n/static/e0b6e8978e250d40d864acc016ecc9f4/c77ca/markdownTestHeader.jpg 393w,\n/static/e0b6e8978e250d40d864acc016ecc9f4/51ce9/markdownTestHeader.jpg 786w,\n/static/e0b6e8978e250d40d864acc016ecc9f4/bc3a8/markdownTestHeader.jpg 800w","srcWebp":"/static/e0b6e8978e250d40d864acc016ecc9f4/6baea/markdownTestHeader.webp","srcSetWebp":"/static/e0b6e8978e250d40d864acc016ecc9f4/de90f/markdownTestHeader.webp 197w,\n/static/e0b6e8978e250d40d864acc016ecc9f4/8a853/markdownTestHeader.webp 393w,\n/static/e0b6e8978e250d40d864acc016ecc9f4/6baea/markdownTestHeader.webp 786w,\n/static/e0b6e8978e250d40d864acc016ecc9f4/c6096/markdownTestHeader.webp 800w","sizes":"(max-width: 786px) 100vw, 786px"}}}}}},"pageContext":{"isCreatedByStatefulCreatePages":false}}}